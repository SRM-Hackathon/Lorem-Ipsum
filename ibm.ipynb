{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ibmos2spark\n",
      "  Downloading https://files.pythonhosted.org/packages/c6/81/1edb24382edef1ca636e87972b2da286b8271a586c728a21f916d3cd76cd/ibmos2spark-1.0.1-py2.py3-none-any.whl\n",
      "Installing collected packages: ibmos2spark\n",
      "Successfully installed ibmos2spark-1.0.1\n",
      "Collecting pixiedust\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/a8/e84b2ed12ee387589c099734b6f914a520e1fef2733c955982623080e813/pixiedust-1.1.17.tar.gz (197kB)\n",
      "\u001b[K    100% |████████████████████████████████| 204kB 573kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting mpld3 (from pixiedust)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
      "\u001b[K    100% |████████████████████████████████| 798kB 302kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: lxml in /home/admin1/anaconda3/lib/python3.7/site-packages (from pixiedust) (4.2.5)\n",
      "Collecting geojson (from pixiedust)\n",
      "  Downloading https://files.pythonhosted.org/packages/e4/8d/9e28e9af95739e6d2d2f8d4bef0b3432da40b7c3588fbad4298c1be09e48/geojson-2.5.0-py2.py3-none-any.whl\n",
      "Collecting astunparse (from pixiedust)\n",
      "  Downloading https://files.pythonhosted.org/packages/2e/37/5dd0dd89b87bb5f0f32a7e775458412c52d78f230ab8d0c65df6aabc4479/astunparse-1.6.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: markdown in /home/admin1/anaconda3/lib/python3.7/site-packages (from pixiedust) (3.0.1)\n",
      "Collecting colour (from pixiedust)\n",
      "  Downloading https://files.pythonhosted.org/packages/74/46/e81907704ab203206769dee1385dc77e1407576ff8f50a0681d0a6b541be/colour-0.1.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: requests in /home/admin1/anaconda3/lib/python3.7/site-packages (from pixiedust) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel<1.0,>=0.23.0 in /home/admin1/anaconda3/lib/python3.7/site-packages (from astunparse->pixiedust) (0.32.3)\n",
      "Requirement already satisfied, skipping upgrade: six<2.0,>=1.6.1 in /home/admin1/anaconda3/lib/python3.7/site-packages (from astunparse->pixiedust) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /home/admin1/anaconda3/lib/python3.7/site-packages (from requests->pixiedust) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /home/admin1/anaconda3/lib/python3.7/site-packages (from requests->pixiedust) (1.24.1)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/admin1/anaconda3/lib/python3.7/site-packages (from requests->pixiedust) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/admin1/anaconda3/lib/python3.7/site-packages (from requests->pixiedust) (2018.11.29)\n",
      "Building wheels for collected packages: pixiedust, mpld3\n",
      "  Running setup.py bdist_wheel for pixiedust ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/admin1/.cache/pip/wheels/25/fa/a5/09c1e8f4c91b34c5f7f4ac6e41be81dd0667030a2372546a8d\n",
      "  Running setup.py bdist_wheel for mpld3 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/admin1/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
      "Successfully built pixiedust mpld3\n",
      "Installing collected packages: mpld3, geojson, astunparse, colour, pixiedust\n",
      "Successfully installed astunparse-1.6.2 colour-0.1.5 geojson-2.5.0 mpld3-0.3 pixiedust-1.1.17\n",
      "Collecting watson-machine-learning-client\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/5c/be0d3efe27704bbd43481b7de364ade8c686e867617caba8654989e0864b/watson_machine_learning_client-1.0.375-py3-none-any.whl (536kB)\n",
      "\u001b[K    100% |████████████████████████████████| 542kB 279kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting ibm-cos-sdk (from watson-machine-learning-client)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/54/381e37afdac8c4b1059fdbb0e9ecfe28c3e385ec2782fb8c415793d6f3ed/ibm-cos-sdk-2.5.4.tar.gz (52kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 291kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting lomond (from watson-machine-learning-client)\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/b1/02eebed49c754b01b17de7705caa8c4ceecfb4f926cdafc220c863584360/lomond-0.3.3-py2.py3-none-any.whl\n",
      "Collecting tabulate (from watson-machine-learning-client)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/d4/977fdd5186b7cdbb7c43a7aac7c5e4e0337a84cb802e154616f3cfc84563/tabulate-0.8.5.tar.gz (45kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 311kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /home/admin1/anaconda3/lib/python3.7/site-packages (from watson-machine-learning-client) (4.28.1)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /home/admin1/anaconda3/lib/python3.7/site-packages (from watson-machine-learning-client) (0.23.4)\n",
      "Requirement already satisfied, skipping upgrade: requests in /home/admin1/anaconda3/lib/python3.7/site-packages (from watson-machine-learning-client) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /home/admin1/anaconda3/lib/python3.7/site-packages (from watson-machine-learning-client) (2018.11.29)\n",
      "Requirement already satisfied, skipping upgrade: urllib3 in /home/admin1/anaconda3/lib/python3.7/site-packages (from watson-machine-learning-client) (1.24.1)\n",
      "Collecting ibm-cos-sdk-core>=2.0.0 (from ibm-cos-sdk->watson-machine-learning-client)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/19/5e41dd03cf9c5b6f953b28199b02e0ece55ef8d4b724b80750cb6761f976/ibm-cos-sdk-core-2.5.4.tar.gz (751kB)\n",
      "\u001b[K    100% |████████████████████████████████| 757kB 306kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting ibm-cos-sdk-s3transfer>=2.0.0 (from ibm-cos-sdk->watson-machine-learning-client)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/91/99c14759514446c1058b0a66754c646f83e29e41e6f2e3f7711356a16933/ibm-cos-sdk-s3transfer-2.5.4.tar.gz (133kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 271kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from ibm-cos-sdk->watson-machine-learning-client)\n",
      "  Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /home/admin1/anaconda3/lib/python3.7/site-packages (from lomond->watson-machine-learning-client) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /home/admin1/anaconda3/lib/python3.7/site-packages (from pandas->watson-machine-learning-client) (2.7.5)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /home/admin1/anaconda3/lib/python3.7/site-packages (from pandas->watson-machine-learning-client) (2018.7)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /home/admin1/anaconda3/lib/python3.7/site-packages (from pandas->watson-machine-learning-client) (1.14.5)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/admin1/anaconda3/lib/python3.7/site-packages (from requests->watson-machine-learning-client) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /home/admin1/anaconda3/lib/python3.7/site-packages (from requests->watson-machine-learning-client) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /home/admin1/anaconda3/lib/python3.7/site-packages (from ibm-cos-sdk-core>=2.0.0->ibm-cos-sdk->watson-machine-learning-client) (0.14)\n",
      "Building wheels for collected packages: ibm-cos-sdk, tabulate, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer\n",
      "  Running setup.py bdist_wheel for ibm-cos-sdk ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/admin1/.cache/pip/wheels/6f/90/cc/78216d4fb08b6736364c4c68da6662feafc1094c4dd17f47c7\n",
      "  Running setup.py bdist_wheel for tabulate ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/admin1/.cache/pip/wheels/e1/41/5e/e201f95d90fc84f93aa629b6638adacda680fe63aac47174ab\n",
      "  Running setup.py bdist_wheel for ibm-cos-sdk-core ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/admin1/.cache/pip/wheels/fc/44/91/3ac9ece0b3759e16ec32ff19e7ea09a9ae10ef5a9e175810b3\n",
      "  Running setup.py bdist_wheel for ibm-cos-sdk-s3transfer ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/admin1/.cache/pip/wheels/d6/e3/e6/e3adc8d4bace3d11c5a96658a1cd3eceeabeb41fdc788e19aa\n",
      "Successfully built ibm-cos-sdk tabulate ibm-cos-sdk-core ibm-cos-sdk-s3transfer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: jmespath, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer, ibm-cos-sdk, lomond, tabulate, watson-machine-learning-client\n",
      "Successfully installed ibm-cos-sdk-2.5.4 ibm-cos-sdk-core-2.5.4 ibm-cos-sdk-s3transfer-2.5.4 jmespath-0.9.4 lomond-0.3.3 tabulate-0.8.5 watson-machine-learning-client-1.0.375\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade ibmos2spark\n",
    "!pip install --upgrade pixiedust\n",
    "!pip install --upgrade watson-machine-learning-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.17</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.clustering import KMeansModel\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=listdir('/home/admin1/srmhack/places_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monuments.csv',\n",
       " 'Bars.csv',\n",
       " 'Places_of_Worship.csv',\n",
       " 'Amusement_Parks.csv',\n",
       " 'Hotels_and_Restaurants.csv',\n",
       " 'Museums.csv',\n",
       " 'Street_food.csv',\n",
       " 'Wildlife.csv',\n",
       " 'Shopping_and_bazaar.csv',\n",
       " 'Galleries.csv',\n",
       " 'Parks_and_Lakes.csv']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[4000, 4000, 4000, 4000, 4000, 3000, 4000, 4000, 4000, 2000, 4000]\n",
    "o=0\n",
    "for i in w:\n",
    "    \n",
    "    df= pd.read_csv('/home/admin1/srmhack/places_data/'+i)\n",
    "    \n",
    "    df = df.iloc[:l[o]]\n",
    "    o=o+1\n",
    "    df.to_csv('/home/admin1/srmhack/train_data_small/'+i)\n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/home/admin1/srmhack/train_data_small/Galleries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd=pd.read_csv('/home/admin1/srmhack/places_data/Museums.csv')\n",
    "df=df.append(dd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/home/admin1/srmhack/train_data_small/Educational.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>place_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105562</td>\n",
       "      <td>P013</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100255</td>\n",
       "      <td>P018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102367</td>\n",
       "      <td>P002</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103961</td>\n",
       "      <td>P025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100977</td>\n",
       "      <td>P018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>105533</td>\n",
       "      <td>P028</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>108856</td>\n",
       "      <td>P019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>107724</td>\n",
       "      <td>P003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>101877</td>\n",
       "      <td>P002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>105742</td>\n",
       "      <td>P003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>109526</td>\n",
       "      <td>P018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>101950</td>\n",
       "      <td>P005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>101864</td>\n",
       "      <td>P025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>101375</td>\n",
       "      <td>P027</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>102146</td>\n",
       "      <td>P027</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>107687</td>\n",
       "      <td>P018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>108622</td>\n",
       "      <td>P017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>104484</td>\n",
       "      <td>P014</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>108494</td>\n",
       "      <td>P024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>106751</td>\n",
       "      <td>P015</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100368</td>\n",
       "      <td>P028</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>101630</td>\n",
       "      <td>P003</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>106356</td>\n",
       "      <td>P019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>105474</td>\n",
       "      <td>P016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>103768</td>\n",
       "      <td>P017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>109319</td>\n",
       "      <td>P004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100008</td>\n",
       "      <td>P018</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>103461</td>\n",
       "      <td>P022</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>105448</td>\n",
       "      <td>P007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>101708</td>\n",
       "      <td>P019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7970</th>\n",
       "      <td>104862</td>\n",
       "      <td>P026</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7971</th>\n",
       "      <td>109037</td>\n",
       "      <td>P027</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7972</th>\n",
       "      <td>102751</td>\n",
       "      <td>P030</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7973</th>\n",
       "      <td>101393</td>\n",
       "      <td>P007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7974</th>\n",
       "      <td>108971</td>\n",
       "      <td>P014</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7975</th>\n",
       "      <td>102331</td>\n",
       "      <td>P006</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7976</th>\n",
       "      <td>102721</td>\n",
       "      <td>P027</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7977</th>\n",
       "      <td>109466</td>\n",
       "      <td>P024</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7978</th>\n",
       "      <td>107321</td>\n",
       "      <td>P010</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7979</th>\n",
       "      <td>101223</td>\n",
       "      <td>P023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7980</th>\n",
       "      <td>106038</td>\n",
       "      <td>P017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7981</th>\n",
       "      <td>107700</td>\n",
       "      <td>P011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7982</th>\n",
       "      <td>108052</td>\n",
       "      <td>P026</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7983</th>\n",
       "      <td>106313</td>\n",
       "      <td>P019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7984</th>\n",
       "      <td>105197</td>\n",
       "      <td>P027</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7985</th>\n",
       "      <td>109162</td>\n",
       "      <td>P026</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7986</th>\n",
       "      <td>107043</td>\n",
       "      <td>P031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7987</th>\n",
       "      <td>102432</td>\n",
       "      <td>P005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7988</th>\n",
       "      <td>105402</td>\n",
       "      <td>P006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7989</th>\n",
       "      <td>101667</td>\n",
       "      <td>P018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7990</th>\n",
       "      <td>104831</td>\n",
       "      <td>P001</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7991</th>\n",
       "      <td>101421</td>\n",
       "      <td>P027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7992</th>\n",
       "      <td>100812</td>\n",
       "      <td>P019</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7993</th>\n",
       "      <td>103000</td>\n",
       "      <td>P008</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>104252</td>\n",
       "      <td>P024</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>106401</td>\n",
       "      <td>P021</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>108568</td>\n",
       "      <td>P015</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>102879</td>\n",
       "      <td>P005</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>104380</td>\n",
       "      <td>P004</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>108744</td>\n",
       "      <td>P013</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id place_id  rating\n",
       "0      105562     P013       4\n",
       "1      100255     P018       3\n",
       "2      102367     P002       4\n",
       "3      103961     P025       0\n",
       "4      100977     P018       4\n",
       "5      105533     P028       4\n",
       "6      108856     P019       1\n",
       "7      107724     P003       2\n",
       "8      101877     P002       3\n",
       "9      105742     P003       1\n",
       "10     109526     P018       1\n",
       "11     101950     P005       2\n",
       "12     101864     P025       1\n",
       "13     101375     P027       2\n",
       "14     102146     P027       5\n",
       "15     107687     P018       3\n",
       "16     108622     P017       1\n",
       "17     104484     P014       2\n",
       "18     108494     P024       0\n",
       "19     106751     P015       3\n",
       "20     100368     P028       4\n",
       "21     101630     P003       5\n",
       "22     106356     P019       3\n",
       "23     105474     P016       5\n",
       "24     103768     P017       2\n",
       "25     109319     P004       1\n",
       "26     100008     P018       5\n",
       "27     103461     P022       2\n",
       "28     105448     P007       0\n",
       "29     101708     P019       1\n",
       "...       ...      ...     ...\n",
       "7970   104862     P026       2\n",
       "7971   109037     P027       5\n",
       "7972   102751     P030       2\n",
       "7973   101393     P007       1\n",
       "7974   108971     P014       2\n",
       "7975   102331     P006       5\n",
       "7976   102721     P027       5\n",
       "7977   109466     P024       2\n",
       "7978   107321     P010       5\n",
       "7979   101223     P023       0\n",
       "7980   106038     P017       2\n",
       "7981   107700     P011       0\n",
       "7982   108052     P026       3\n",
       "7983   106313     P019       3\n",
       "7984   105197     P027       5\n",
       "7985   109162     P026       2\n",
       "7986   107043     P031       1\n",
       "7987   102432     P005       0\n",
       "7988   105402     P006       0\n",
       "7989   101667     P018       1\n",
       "7990   104831     P001       5\n",
       "7991   101421     P027       0\n",
       "7992   100812     P019       4\n",
       "7993   103000     P008       5\n",
       "7994   104252     P024       5\n",
       "7995   106401     P021       3\n",
       "7996   108568     P015       2\n",
       "7997   102879     P005       5\n",
       "7998   104380     P004       5\n",
       "7999   108744     P013       5\n",
       "\n",
       "[8000 rows x 3 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>place_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105562</td>\n",
       "      <td>P013</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100255</td>\n",
       "      <td>P018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102367</td>\n",
       "      <td>P002</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103961</td>\n",
       "      <td>P025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100977</td>\n",
       "      <td>P018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>105533</td>\n",
       "      <td>P028</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>108856</td>\n",
       "      <td>P019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>107724</td>\n",
       "      <td>P003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>101877</td>\n",
       "      <td>P002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>105742</td>\n",
       "      <td>P003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>109526</td>\n",
       "      <td>P018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>101950</td>\n",
       "      <td>P005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>101864</td>\n",
       "      <td>P025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>101375</td>\n",
       "      <td>P027</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>102146</td>\n",
       "      <td>P027</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>107687</td>\n",
       "      <td>P018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>108622</td>\n",
       "      <td>P017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>104484</td>\n",
       "      <td>P014</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>108494</td>\n",
       "      <td>P024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>106751</td>\n",
       "      <td>P015</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100368</td>\n",
       "      <td>P028</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>101630</td>\n",
       "      <td>P003</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>106356</td>\n",
       "      <td>P019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>105474</td>\n",
       "      <td>P016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>103768</td>\n",
       "      <td>P017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>109319</td>\n",
       "      <td>P004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100008</td>\n",
       "      <td>P018</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>103461</td>\n",
       "      <td>P022</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>105448</td>\n",
       "      <td>P007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>101708</td>\n",
       "      <td>P019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>105075</td>\n",
       "      <td>P017</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>108287</td>\n",
       "      <td>P009</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>101220</td>\n",
       "      <td>P017</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>108909</td>\n",
       "      <td>P020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>100015</td>\n",
       "      <td>P009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>100163</td>\n",
       "      <td>P013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>103308</td>\n",
       "      <td>P016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>107790</td>\n",
       "      <td>P012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>106170</td>\n",
       "      <td>P026</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>109549</td>\n",
       "      <td>P001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>100353</td>\n",
       "      <td>P001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>106741</td>\n",
       "      <td>P031</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>100993</td>\n",
       "      <td>P014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>107254</td>\n",
       "      <td>P012</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>104115</td>\n",
       "      <td>P005</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>108129</td>\n",
       "      <td>P018</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>101234</td>\n",
       "      <td>P031</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>103577</td>\n",
       "      <td>P025</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>100763</td>\n",
       "      <td>P030</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>108985</td>\n",
       "      <td>P029</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>107923</td>\n",
       "      <td>P028</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>104796</td>\n",
       "      <td>P003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>101581</td>\n",
       "      <td>P006</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>100210</td>\n",
       "      <td>P007</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>109052</td>\n",
       "      <td>P019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>107466</td>\n",
       "      <td>P017</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>103991</td>\n",
       "      <td>P019</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>107418</td>\n",
       "      <td>P003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>100864</td>\n",
       "      <td>P028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>106823</td>\n",
       "      <td>P020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id place_id  rating\n",
       "0     105562     P013       4\n",
       "1     100255     P018       3\n",
       "2     102367     P002       4\n",
       "3     103961     P025       0\n",
       "4     100977     P018       4\n",
       "5     105533     P028       4\n",
       "6     108856     P019       1\n",
       "7     107724     P003       2\n",
       "8     101877     P002       3\n",
       "9     105742     P003       1\n",
       "10    109526     P018       1\n",
       "11    101950     P005       2\n",
       "12    101864     P025       1\n",
       "13    101375     P027       2\n",
       "14    102146     P027       5\n",
       "15    107687     P018       3\n",
       "16    108622     P017       1\n",
       "17    104484     P014       2\n",
       "18    108494     P024       0\n",
       "19    106751     P015       3\n",
       "20    100368     P028       4\n",
       "21    101630     P003       5\n",
       "22    106356     P019       3\n",
       "23    105474     P016       5\n",
       "24    103768     P017       2\n",
       "25    109319     P004       1\n",
       "26    100008     P018       5\n",
       "27    103461     P022       2\n",
       "28    105448     P007       0\n",
       "29    101708     P019       1\n",
       "..       ...      ...     ...\n",
       "970   105075     P017       4\n",
       "971   108287     P009       4\n",
       "972   101220     P017       3\n",
       "973   108909     P020       0\n",
       "974   100015     P009       1\n",
       "975   100163     P013       0\n",
       "976   103308     P016       3\n",
       "977   107790     P012       0\n",
       "978   106170     P026       4\n",
       "979   109549     P001       1\n",
       "980   100353     P001       1\n",
       "981   106741     P031       5\n",
       "982   100993     P014       0\n",
       "983   107254     P012       3\n",
       "984   104115     P005       5\n",
       "985   108129     P018       5\n",
       "986   101234     P031       4\n",
       "987   103577     P025       4\n",
       "988   100763     P030       5\n",
       "989   108985     P029       2\n",
       "990   107923     P028       2\n",
       "991   104796     P003       0\n",
       "992   101581     P006       2\n",
       "993   100210     P007       2\n",
       "994   109052     P019       1\n",
       "995   107466     P017       3\n",
       "996   103991     P019       4\n",
       "997   107418     P003       3\n",
       "998   100864     P028       0\n",
       "999   106823     P020       2\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     df = df.iloc[:30000]\n",
    "    \n",
    "#     df.to_csv('/home/admin1/srmhack/train_data_small/'+i)\n",
    "    \n",
    "#     s=len(educational)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd=pd.read_csv('/home/admin1/srmhack/places_data/Wildlife.csv')\n",
    "educational=educational.append(dd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "educational.to_csv('/home/admin1/srmhack/train_data_small/Adventuretrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "l=[]\n",
    "for i in range(x):\n",
    "    l.append(random.randrange(1,6,1))\n",
    "df['avid']=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/home/admin1/srmhack/train_data/Educationaltrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adventure=df.loc[:,['user_id','Amusement Parks', 'Bars', 'Parks', 'Restaurant', 'Wildlife']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "adventure.to_csv('/home/admin1/srmhack/adventure.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreation=df.loc[:,['user_id', 'Amusement Parks', 'Bars','Parks', 'Restaurant', 'Shopping',\n",
    "       'Street Food']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreation.to_csv('/home/admin1/srmhack/recreation.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment=df.loc[:,['user_id','Parks', 'Wildlife']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.to_csv('/home/admin1/srmhack/separated_types/environment.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "religious=df.loc[:,['user_id', 'Places of Worship']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "religious.to_csv('/home/admin1/srmhack/separated_types/religious.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cultural_heritage=df.loc[:,['user_id', 'Galleries', 'Monuments',\n",
    "       'Museums', 'Places of Worship']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cultural_heritage.to_csv('/home/admin1/srmhack/separated_types/cultural_heritage.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "educational=df.loc[:,['user_id', 'Galleries', 'Monuments',\n",
    "       'Museums']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "educational.to_csv('/home/admin1/srmhack/separated_types/educational.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------adventure model------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'userid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f309bf21b815>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madventure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#predictions = model.predict(data1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    969\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m                 return_n_iter=True)\n\u001b[0m\u001b[1;32m    972\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mk_means\u001b[0;34m(X, n_clusters, sample_weight, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"C\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy_x\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     X = check_array(X, accept_sparse='csr', dtype=[np.float64, np.float32],\n\u001b[0;32m--> 311\u001b[0;31m                     order=order, copy=copy_x)\n\u001b[0m\u001b[1;32m    312\u001b[0m     \u001b[0;31m# verify that the number of samples given is larger than k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'userid'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = KMeans(n_clusters = 10).fit(adventure.loc[:,['Amusement Parks', 'Bars', 'Parks', 'Restaurant', 'Wildlife']]])\n",
    "#predictions = model.predict(data1)\n",
    "\n",
    "#y1_pred = km.fit_predict(final[['0', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9',\n",
    "  #     '0.10']])\n",
    "pickle.dump(model, open('/home/admin1/WMN/clusmodel','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('/home/admin1/srmhack/train_data/Adventuretrain.csv') # reading data in pandas df\n",
    "\n",
    "from surprise import Reader, Dataset\n",
    "\n",
    "# to load dataset from pandas df, we need `load_fromm_df` method in surprise lib\n",
    "\n",
    "ratings_dict = {'placeid': list(ratings.place_id),\n",
    "                'userid': list(ratings.user_id),\n",
    "                'rating': list(ratings.rating),'avid': list(ratings.avid)}\n",
    "df = pd.DataFrame(ratings_dict)\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is required.\n",
    "# The Reader class is used to parse a file containing ratings.\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(df[['userid', 'placeid', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pickle\n",
    "feature_files=['Educationaltrain.csv','Environmenttrain.csv','Religioustrain.csv','CulturalHeritagetrain.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adventuretrain.csv\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-181-c87d3c92e3bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNNBasic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsl_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbsl_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msim_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RMSE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MAE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;31m#     trainset = data.build_full_trainset()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#     algo.train(trainset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/surprise/evaluate.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(algo, data, measures, with_dump, dump_dir, verbose)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# train and test algorithm. Keep all rating predictions in a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/surprise/prediction_algorithms/knns.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, trainset)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mSymmetricAlgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_similarities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/surprise/prediction_algorithms/algo_base.py\u001b[0m in \u001b[0;36mcompute_similarities\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Computing the {0} similarity matrix...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruction_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done computing similarity matrix.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/surprise/similarities.pyx\u001b[0m in \u001b[0;36msurprise.similarities.pearson_baseline\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(0,5))\n",
    "model_path = \"/home/admin1/srmhack/model/\"\n",
    "for i in feature_files:\n",
    "    print(i)\n",
    "    df = pd.read_csv('/home/admin1/srmhack/train_data/' + i,sep=',', error_bad_lines=False, encoding=\"latin-1\")\n",
    "    data = Dataset.load_from_df(df.loc[:,['userid', 'placeid', 'rating']],reader)\n",
    "    \n",
    "    \n",
    "    #algo = SVD()\n",
    "\n",
    "# Train and test reporting the RMSE and MAE scores\n",
    "   \n",
    "# Retrieve the trainset.\n",
    "    \n",
    "\n",
    "# Predict a certain item\n",
    "#     userid = str(196)\n",
    "#     placeid = str(302)\n",
    "#     actual_rating = 4\n",
    "#     print(algo.predict(userid, placeid, actual_rating))\n",
    "    bsl_options = {'method': 'als',\n",
    "               'n_epochs': 20,\n",
    "               }\n",
    "    sim_options = {'name': 'pearson_baseline'}\n",
    "    algo = KNNBasic(bsl_options=bsl_options, sim_options=sim_options)\n",
    "    data.split(n_folds=10)\n",
    "    evaluate(algo, data, measures=['RMSE', 'MAE'])\n",
    "#     trainset = data.build_full_trainset()\n",
    "#     algo.train(trainset)\n",
    "#     cross_validate(algo, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "#     trainset, testset = train_test_split(data, test_size=0.35)\n",
    "#     algo = KNNBasic(bsl_options=bsl_options)\n",
    "#     predictions = algo.fit(trainset).test(testset)\n",
    "#     accuracy.rmse(predictions)\n",
    "\n",
    "    file = model_path + i.split('.')[0] + '.pkl'\n",
    "    print(file)\n",
    "    pickle.dump(algo,open(file,'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm BaselineOnly.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "Estimating biases using als...\n",
      "RMSE: 1.7140\n",
      "MAE:  1.5057\n",
      "------------\n",
      "Fold 2\n",
      "Estimating biases using als...\n",
      "RMSE: 1.7228\n",
      "MAE:  1.5144\n",
      "------------\n",
      "Fold 3\n",
      "Estimating biases using als...\n",
      "RMSE: 1.7015\n",
      "MAE:  1.4919\n",
      "------------\n",
      "Fold 4\n",
      "Estimating biases using als...\n",
      "RMSE: 1.7144\n",
      "MAE:  1.5076\n",
      "------------\n",
      "Fold 5\n",
      "Estimating biases using als...\n",
      "RMSE: 1.6864\n",
      "MAE:  1.4726\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 1.7078\n",
      "Mean MAE : 1.4984\n",
      "------------\n",
      "------------\n",
      "Estimating biases using als...\n",
      "user: 196        item: 302        r_ui = 4.00   est = 2.50   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "data.split(n_folds=5)\n",
    "bsl_options = {'method': 'als',\n",
    "               'n_epochs': 20,\n",
    "               }\n",
    "algo = BaselineOnly (bsl_options=bsl_options)\n",
    "\n",
    "# Train and test reporting the RMSE and MAE scores\n",
    "evaluate(algo, data, measures=['RMSE', 'MAE'])\n",
    "\n",
    "# Retrieve the trainset.\n",
    "trainset = data.build_full_trainset()\n",
    "algo.train(trainset)\n",
    "\n",
    "# Predict a certain item\n",
    "userid = str(196)\n",
    "itemid = str(302)\n",
    "actual_rating = 4\n",
    "print(algo.predict(userid, itemid, actual_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 196        item: 302        r_ui = 4.00   est = 2.50   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "userid = str(196)\n",
    "placeid = str(302)\n",
    "actual_rating = 4\n",
    "print(algo.predict(userid, placeid, actual_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.split(n_folds=5)\n",
    "\n",
    "from surprise import SVD, evaluate\n",
    "from surprise import NMF\n",
    "\n",
    "# svd\n",
    "bsl_options = {'method': 'als',\n",
    "               'n_epochs': 20,\n",
    "               }\n",
    "sim_options = {'name': 'pearson_baseline'}\n",
    "algo = KNNBasic(bsl_options=bsl_options, sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Educational.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1472: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE: 1.6998\n",
      "/home/admin1/srmhack/model_small/Educational.pkl\n",
      "Environmenttrain.csv\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE: 1.7151\n",
      "/home/admin1/srmhack/model_small/Environmenttrain.pkl\n",
      "Religioustrain.csv\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE: 1.6877\n",
      "/home/admin1/srmhack/model_small/Religioustrain.pkl\n",
      "CulturalHeritagetrain.csv\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE: 1.7068\n",
      "/home/admin1/srmhack/model_small/CulturalHeritagetrain.pkl\n",
      "Adventuretrain.csv\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE: 1.6896\n",
      "/home/admin1/srmhack/model_small/Adventuretrain.pkl\n",
      "Recreationtrain.csv\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE: 1.7036\n",
      "/home/admin1/srmhack/model_small/Recreationtrain.pkl\n"
     ]
    }
   ],
   "source": [
    "feature=['Educational.csv','Environmenttrain.csv','Religioustrain.csv','CulturalHeritagetrain.csv','Adventuretrain.csv','Recreationtrain.csv']\n",
    "reader = Reader(rating_scale=(0,5))\n",
    "model_path = \"/home/admin1/srmhack/model_small/\"\n",
    "for i in feature:\n",
    "    print(i)\n",
    "    df = pd.read_csv('/home/admin1/srmhack/train_data_small/' + i, error_bad_lines=False, encoding=\"latin-1\")\n",
    "    data = Dataset.load_from_df(df.loc[:,['userid', 'placeid', 'rating']],reader)\n",
    "    bsl_options = {'method': 'als',\n",
    "               'n_epochs':10,\n",
    "               'reg_u': 12,\n",
    "               'reg_i': 5\n",
    "               }\n",
    "    data.split(n_folds=5)\n",
    "    cross_validate(algo, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "    trainset, testset = train_test_split(data, test_size=0.25)\n",
    "    algo = BaselineOnly(bsl_options=bsl_options)\n",
    "    predictions = algo.fit(trainset).test(testset)\n",
    "    accuracy.rmse(predictions)\n",
    "\n",
    "    file = model_path + i.split('.')[0] + '.pkl'\n",
    "    print(file)\n",
    "    pickle.dump(algo,open(file,'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/admin1/srmhack/train_data_small/Educational.csv')\n",
    "l=df.place_id.unique()\n",
    "df=pd.read_csv('/home/admin1/srmhack/Original data.csv')\n",
    "df = df[df['ID'].isin(list(l))] \n",
    "z=list(df.ID.unique())\n",
    "p=list(df.NAME.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P076'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "i=0\n",
    "for key in z:\n",
    "    dic[key]=p[i]\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P032': 'Bangalore Fort',\n",
       " 'P033': 'Bangalore Palace',\n",
       " 'P034': 'Ashoka Pillar Monument',\n",
       " 'P035': \"Tipu Sultan's Summer Palace\",\n",
       " 'P036': 'Kempegowda Tower (South West)',\n",
       " 'P037': \"Tipu Sultan's Armoury\",\n",
       " 'P038': 'Devanahalli Fort',\n",
       " 'P039': 'Visvesvaraya Industrial & Technological Museum',\n",
       " 'P040': 'Victoria Hospital',\n",
       " 'P041': 'Sds Sanatorium',\n",
       " 'P042': 'Minto Ophthalmic Hospital',\n",
       " 'P043': 'Kidwai Memorial Institute of Oncology',\n",
       " 'P044': 'Government Museum',\n",
       " 'P045': 'HAL Heritage Centre and Aerospace Museum',\n",
       " 'P046': 'Venkatappa Art Gallery',\n",
       " 'P047': 'NIMHANS Brain Museum',\n",
       " 'P048': 'National Gallery of Modern Art, Bangalore',\n",
       " 'P049': 'Kempegowda Museum',\n",
       " 'P050': 'Indian Music Experience',\n",
       " 'P051': 'Indian Military Museum',\n",
       " 'P052': \"Girias Children's Explorium\",\n",
       " 'P053': 'Click Art Museum',\n",
       " 'P054': 'Shaswathi Womens Heritage Museum',\n",
       " 'P055': 'RAMANEEYA MUSEUM',\n",
       " 'P056': 'MKF Museum of Art',\n",
       " 'P057': 'Department of Archaeology and Museums',\n",
       " 'P058': 'Vintage Car Park',\n",
       " 'P059': 'ReReeti',\n",
       " 'P060': 'NIMHANS Heritage Museum',\n",
       " 'P061': 'Peepletree Art Gallery',\n",
       " 'P062': 'Rail Cartoon Gallery',\n",
       " 'P063': 'SHADES CREATIVE GALLERY',\n",
       " 'P064': 'Cauvery Karnataka State Arts & Craft Emporium',\n",
       " 'P065': 'Matsya Loka Aquarium Gallery',\n",
       " 'P066': 'Jennard Galleries(Art Galleries in Bangalore,Galleries)',\n",
       " 'P067': 'Chitra Sante',\n",
       " 'P068': 'Shades Creative Learning',\n",
       " 'P069': 'Shalom Arts and Crafts',\n",
       " 'P070': 'Fear Tattoo Studio',\n",
       " 'P071': 'Karnataka Chitrakala Parishath',\n",
       " 'P072': 'Mahua- The Art Gallery',\n",
       " 'P073': 'Gallery Sumukha',\n",
       " 'P074': 'Life on Wall Art Gallery',\n",
       " 'P075': 'Crimson Art Gallery'}"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
